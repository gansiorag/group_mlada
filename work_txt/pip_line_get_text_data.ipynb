{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DD = '/home/al/Projects_My/hakaton_ozon_org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение списка стоп слов\n",
    "stop_words = []\n",
    "with open(PATH_DD + 'dataset/stop_word_base.txt', 'r') as f:\n",
    "    for i in f:\n",
    "        stop_words.append(i.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir(NAME_START: str) -> list:\n",
    "    '''Получение списка директорий наборов\n",
    "    '''\n",
    "    dd = [ f.path for f in os.scandir(NAME_START) if f.is_dir() ]\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(value):\n",
    "    for i in range(10):\n",
    "        value = value.replace(str(i),'')\n",
    "    value = value.replace('(-)', ' ')\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_text_with_category(nf: str, m):\n",
    "    \"\"\" Получение массива текстов по категориям\n",
    "\n",
    "    Args:\n",
    "        nf (str): _description_\n",
    "        m (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    ddel = ['*', ',', '-', '/', '%', ';', ')', '+', '.', '..', ':']\n",
    "    with open(nf, 'r') as i_f:\n",
    "        all_text = i_f.read()\n",
    "        all_text = all_text.strip().rstrip('\\r\\n')\n",
    "        all_text = func(all_text)\n",
    "        #.replace('/\\n', ' ')\n",
    "        for i in ddel:\n",
    "            all_text = all_text.replace(i, ' ')\n",
    "        all_text = all_text.lower().split()\n",
    "    sum_arr = []\n",
    "    for word in all_text:\n",
    "        # print(word)\n",
    "        lemmas = m.lemmatize(word)\n",
    "        # doc = Doc(word)\n",
    "        # print(doc.tokens)\n",
    "        # print(doc.sents)\n",
    "        # print(lemmas)\n",
    "        # print()\n",
    "        if lemmas[0] not in stop_words:\n",
    "            sum_arr.append(lemmas[0])\n",
    "        #break\n",
    "    return sum_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "чехлы\n",
      "наушники\n",
      "платья\n",
      "['чехлы', 'наушники', 'платья']\n",
      "32\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "1109\n"
     ]
    }
   ],
   "source": [
    "NAME_START_POINT = PATH_DD + 'dataset_loc/'\n",
    "list_dir = get_dir(NAME_START_POINT)\n",
    "# print(list_dir)\n",
    "list_dir = ['/home/al/Projects_My/hakaton_ozon_org/dataset_loc/чехлы',\n",
    "            '/home/al/Projects_My/hakaton_ozon_org/dataset_loc/Наушники',\n",
    "            '/home/al/Projects_My/hakaton_ozon_org/dataset_loc/платья'\n",
    "]\n",
    "            \n",
    "categories = list_dir.copy()\n",
    "array_txt = [] # описание как предложения из лемматизированных слов\n",
    "m = Mystem()\n",
    "kk = 0\n",
    "catY = []\n",
    "keys_cat = []\n",
    "all_words_list = []\n",
    "for sd in list_dir:\n",
    "    key_one = sd.split('/')[-1].lower()\n",
    "    print(key_one)\n",
    "    keys_cat.append(key_one)\n",
    "    list_dir_two = get_dir(sd)\n",
    "    for dt in list_dir_two:\n",
    "        list_text = glob(dt + '/*.txt')\n",
    "        #print(list_text)\n",
    "        #print()\n",
    "        servis_list = []\n",
    "        # servis_list.append(key_one)\n",
    "        for nf in list_text:\n",
    "            dd = get_array_text_with_category(nf, m)\n",
    "            servis_list += dd\n",
    "            all_words_list += dd\n",
    "            #break\n",
    "        array_txt.append(' '.join(servis_list))\n",
    "        catY.append(kk)\n",
    "        # print()\n",
    "        # print(array_txt[kk])\n",
    "    kk += 1\n",
    "    #break\n",
    "\n",
    "# set_dict = []\n",
    "# for key in array_txt:\n",
    "#     print()\n",
    "#     print(key)\n",
    "#     print(array_txt[key])\n",
    "#     dd = dict(array_txt[key])\n",
    "#     nab = []\n",
    "#     for kk in dd:\n",
    "#         if dd[kk] >=2 and kk not in stop_words:\n",
    "#             nab.append(kk)\n",
    "#     set_dict.append(nab)\n",
    "set_all_words = set(all_words_list)\n",
    "print(keys_cat)\n",
    "print(len(array_txt))\n",
    "print(catY)\n",
    "print(len(set_all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'смартфон накладка камера противоударный силиконовый накладка камера kreiger mix специально спроектировать samsung galaxy a g серьезный периметр обладать усиленный угол смартфон средство воздушный подушка находиться между угол накладка серьезно смягчать удар падение толщина предусматривать камера бортик вокруг камера защищать линза отдельность упругий полиуретан безопасный мягкий ощупь накладка иметься отверстие шнурок помощь смартфон можно носить шея рука силиконовый накладка камера противоударный общий изготовитель мес samsung galaxy a g samsung galaxy a смартфон фиолетовый код продавец'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_txt[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(array_txt, catY, test_size=0.20, random_state=42)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод наивный Байес\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = vectorizer.transform(X_test)\n",
    "#print(X_test_new.shape)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_test_new)\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "2 2\n",
      "model  1.0\n"
     ]
    }
   ],
   "source": [
    "kk = 0\n",
    "for doc, category in zip(y_test, predicted):\n",
    "    print(doc, category)\n",
    "    if doc == category: kk +=1\n",
    "        \n",
    "print('model ', kk/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '1031436306', '11', ..., 'юбка', 'являться', 'яркость'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 5 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(vocabulary={&#x27;a&#x27;, &#x27;aac&#x27;, &#x27;acs&#x27;, &#x27;air&#x27;, &#x27;amoled&#x27;, &#x27;android&#x27;,\n",
       "                            &#x27;apparel&#x27;, &#x27;apple&#x27;, &#x27;aramid&#x27;, &#x27;avakyan&#x27;, &#x27;awesome&#x27;,\n",
       "                            &#x27;bass&#x27;, &#x27;best&#x27;, &#x27;black&#x27;, &#x27;bluetooth&#x27;, &#x27;borofone&#x27;,\n",
       "                            &#x27;boutique&#x27;, &#x27;broscorp&#x27;, &#x27;by&#x27;, &#x27;c&#x27;, &#x27;camera&#x27;, &#x27;case&#x27;,\n",
       "                            &#x27;cavolo&#x27;, &#x27;chrome&#x27;, &#x27;club&#x27;, &#x27;concept&#x27;, &#x27;ew&#x27;,\n",
       "                            &#x27;femme&#x27;, &#x27;fiber&#x27;, &#x27;g&#x27;, ...})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(vocabulary={&#x27;a&#x27;, &#x27;aac&#x27;, &#x27;acs&#x27;, &#x27;air&#x27;, &#x27;amoled&#x27;, &#x27;android&#x27;,\n",
       "                            &#x27;apparel&#x27;, &#x27;apple&#x27;, &#x27;aramid&#x27;, &#x27;avakyan&#x27;, &#x27;awesome&#x27;,\n",
       "                            &#x27;bass&#x27;, &#x27;best&#x27;, &#x27;black&#x27;, &#x27;bluetooth&#x27;, &#x27;borofone&#x27;,\n",
       "                            &#x27;boutique&#x27;, &#x27;broscorp&#x27;, &#x27;by&#x27;, &#x27;c&#x27;, &#x27;camera&#x27;, &#x27;case&#x27;,\n",
       "                            &#x27;cavolo&#x27;, &#x27;chrome&#x27;, &#x27;club&#x27;, &#x27;concept&#x27;, &#x27;ew&#x27;,\n",
       "                            &#x27;femme&#x27;, &#x27;fiber&#x27;, &#x27;g&#x27;, ...})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(vocabulary={'a', 'aac', 'acs', 'air', 'amoled', 'android',\n",
       "                            'apparel', 'apple', 'aramid', 'avakyan', 'awesome',\n",
       "                            'bass', 'best', 'black', 'bluetooth', 'borofone',\n",
       "                            'boutique', 'broscorp', 'by', 'c', 'camera', 'case',\n",
       "                            'cavolo', 'chrome', 'club', 'concept', 'ew',\n",
       "                            'femme', 'fiber', 'g', ...})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('count', CountVectorizer(vocabulary=set_all_words)),\n",
    "                 ('tfid', TfidfTransformer())]).fit(array_txt)\n",
    "# tf_transformer = TfidfTransformer(use_idf=False).fit(array_txt)\n",
    "pipe['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1109)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.transform(array_txt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.49650756, 3.1102132 , 3.80336038, ..., 4.49650756, 4.49650756,\n",
       "       4.49650756])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe['tfid'].idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__getattr__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_arff_parser', '_base', '_california_housing', '_covtype', '_kddcup99', '_lfw', '_olivetti_faces', '_openml', '_rcv1', '_samples_generator', '_species_distributions', '_svmlight_format_fast', '_svmlight_format_io', '_twenty_newsgroups', 'clear_data_home', 'descr', 'dump_svmlight_file', 'fetch_20newsgroups', 'fetch_20newsgroups_vectorized', 'fetch_california_housing', 'fetch_covtype', 'fetch_kddcup99', 'fetch_lfw_pairs', 'fetch_lfw_people', 'fetch_olivetti_faces', 'fetch_openml', 'fetch_rcv1', 'fetch_species_distributions', 'get_data_home', 'load_breast_cancer', 'load_diabetes', 'load_digits', 'load_files', 'load_iris', 'load_linnerud', 'load_sample_image', 'load_sample_images', 'load_svmlight_file', 'load_svmlight_files', 'load_wine', 'make_biclusters', 'make_blobs', 'make_checkerboard', 'make_circles', 'make_classification', 'make_friedman1', 'make_friedman2', 'make_friedman3', 'make_gaussian_quantiles', 'make_hastie_10_2', 'make_low_rank_matrix', 'make_moons', 'make_multilabel_classification', 'make_regression', 'make_s_curve', 'make_sparse_coded_signal', 'make_sparse_spd_matrix', 'make_sparse_uncorrelated', 'make_spd_matrix', 'make_swiss_roll', 'textwrap']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "list_tem = dir(ds)\n",
    "len(list_tem)\n",
    "print(list_tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import __name__\n",
    "dd = load_iris()\n",
    "dd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sklearn.datasets'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"talk.religion.misc\",\n",
    "]\n",
    "\n",
    "# data_train = fetch_20newsgroups(\n",
    "#     subset=\"train\",\n",
    "#     categories=categories,\n",
    "#     shuffle=True,\n",
    "#     random_state=42,\n",
    "#     remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "# )\n",
    "data_all = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: holmes7000@iscsvax.uni.edu\n",
      "Subject: WIn 3.0 ICON HELP PLEASE!\n",
      "Organization: University of Northern Iowa\n",
      "Lines: 10\n",
      "\n",
      "I have win 3.0 and downloaded several icons and BMP's but I can't figure out\n",
      "how to change the \"wallpaper\" or use the icons.  Any help would be appreciated.\n",
      "\n",
      "\n",
      "Thanx,\n",
      "\n",
      "-Brando\n",
      "\n",
      "PS Please E-mail me\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_all.data[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.keys() #['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'talk.religion.misc']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_test = fetch_20newsgroups(\n",
    "    subset=\"test\",\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    ")\n",
    "\n",
    "print(f\"Loading 20 newsgroups dataset for {len(data_train.target_names)} categories:\")\n",
    "print(data_train.target_names)\n",
    "print(f\"{len(data_train.data)} documents\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
