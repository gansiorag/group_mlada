{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка моделей\n",
    "def load_models():\n",
    "    # yolo_v8_model = YOLO('yolov8n.pt')\n",
    "    faster_rcnn_model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True).eval()\n",
    "    # detr_model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\").eval()\n",
    "    # return yolo_v8_model, faster_rcnn_model, detr_model\n",
    "    return faster_rcnn_model\n",
    "\n",
    "\n",
    "# COCO метки\n",
    "# coco_labels = {\n",
    "#     2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck',\n",
    "#     9: 'boat', 10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench',\n",
    "#     16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear',\n",
    "#     24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase',\n",
    "#     34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat',\n",
    "#     40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass',\n",
    "#     47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich',\n",
    "#     55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair',\n",
    "#     63: 'couch', 64: 'potted plant', 65: 'bed', 66: 'remote',  67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop',\n",
    "#     74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven', 80: 'toaster',\n",
    "#     81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear',\n",
    "#     89: 'hair drier', 90: 'toothbrush'\n",
    "# }\n",
    "\n",
    "coco_labels = {\n",
    "    1: 'person',\n",
    "    2: 'bicycle',\n",
    "    3: 'car',\n",
    "    4: 'motorcycle',\n",
    "    5: 'airplane',\n",
    "    6: 'bus',\n",
    "    7: 'train',\n",
    "    8: 'truck',\n",
    "    9: 'boat',\n",
    "    10: 'traffic light',\n",
    "    11: 'fire hydrant',\n",
    "    13: 'stop sign',\n",
    "    14: 'parking meter',\n",
    "    15: 'bench',\n",
    "    16: 'bird',\n",
    "    17: 'cat',\n",
    "    18: 'dog',\n",
    "    19: 'horse',\n",
    "    20: 'sheep',\n",
    "    21: 'cow',\n",
    "    22: 'elephant',\n",
    "    23: 'bear',\n",
    "    24: 'zebra',\n",
    "    25: 'giraffe',\n",
    "    27: 'backpack',\n",
    "    28: 'umbrella',\n",
    "    31: 'handbag',\n",
    "    32: 'tie',\n",
    "    33: 'suitcase',\n",
    "    34: 'frisbee',\n",
    "    35: 'skis',\n",
    "    36: 'snowboard',\n",
    "    37: 'sports ball',\n",
    "    38: 'kite',\n",
    "    39: 'baseball bat',\n",
    "    40: 'baseball glove',\n",
    "    41: 'skateboard',\n",
    "    42: 'surfboard',\n",
    "    43: 'tennis racket',\n",
    "    44: 'bottle',\n",
    "    46: 'wine glass',\n",
    "    47: 'cup',\n",
    "    48: 'fork',\n",
    "    49: 'knife',\n",
    "    50: 'spoon',\n",
    "    51: 'bowl',\n",
    "    52: 'banana',\n",
    "    53: 'apple',\n",
    "    54: 'sandwich',\n",
    "    55: 'orange',\n",
    "    56: 'broccoli',\n",
    "    57: 'carrot',\n",
    "    58: 'hot dog',\n",
    "    59: 'pizza',\n",
    "    60: 'donut',\n",
    "    61: 'cake',\n",
    "    62: 'chair',\n",
    "    63: 'couch',\n",
    "    64: 'potted plant',\n",
    "    65: 'bed',\n",
    "    67: 'dining table',\n",
    "    70: 'toilet',\n",
    "    72: 'tv',\n",
    "    73: 'laptop',\n",
    "    74: 'mouse',\n",
    "    75: 'remote',\n",
    "    76: 'keyboard',\n",
    "    77: 'cell phone',\n",
    "    78: 'microwave',\n",
    "    79: 'oven',\n",
    "    80: 'toaster',\n",
    "    81: 'sink',\n",
    "    82: 'refrigerator',\n",
    "    84: 'book',\n",
    "    85: 'clock',\n",
    "    86: 'vase',\n",
    "    87: 'scissors',\n",
    "    88: 'teddy bear',\n",
    "    89: 'hair drier',\n",
    "    90: 'toothbrush'\n",
    "}\n",
    "\n",
    "\n",
    "# Функция для обработки изображения через Faster R-CNN\n",
    "def detect_objects_faster(faster_rcnn_model, image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = transforms.ToTensor()(image).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        faster_rcnn_results = faster_rcnn_model(image_tensor)[0]\n",
    "\n",
    "    all_results = []\n",
    "    for i in range(len(faster_rcnn_results[\"boxes\"])):\n",
    "        box = faster_rcnn_results[\"boxes\"][i].tolist()\n",
    "        label = coco_labels.get(int(faster_rcnn_results[\"labels\"][i].item()), \"unknown\")\n",
    "        score = faster_rcnn_results[\"scores\"][i].item()\n",
    "        all_results.append({\"box\": box, \"label\": label, \"score\": score, \"source\": \"Faster R-CNN\"})\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Функция для обработки всех изображений в заданных директориях\n",
    "def process_images_in_directories(paths, model, output_dir):\n",
    "    for path in paths:\n",
    "        full_res = []\n",
    "        for dirpath, dirnames, filenames in os.walk(path):\n",
    "            for dirname in dirnames:\n",
    "                dir_path = os.path.join(dirpath, dirname)\n",
    "                if 'desc' not in dir_path:\n",
    "                    current_dir_data = []\n",
    "                    for _, _, filenames in os.walk(dir_path):\n",
    "                        for filename in filenames:\n",
    "                            file = os.path.join(dir_path, filename)\n",
    "                            try:\n",
    "                                current_dir_data.append(detect_objects_faster(model, file))\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing {file}: {e}\")\n",
    "                    full_res.append(current_dir_data)\n",
    "        name = path.rsplit('/', 1)[-1]\n",
    "        save_results(full_res, name, output_dir)\n",
    "\n",
    "# Функция для сохранения результатов\n",
    "def save_results(data, name, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(f'{output_dir}/full_{name}.txt', 'w') as fw:\n",
    "        json.dump(data, fw)\n",
    "\n",
    "# Фильтрация данных без изображений людей\n",
    "def filter_data(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True) \n",
    "    for dirpath, dirnames, filenames in os.walk(input_dir):\n",
    "        for filename in filenames:\n",
    "            objs = []\n",
    "            path = os.path.join(dirpath, filename)\n",
    "            with open(path, 'r') as fr:\n",
    "                lst = json.load(fr)\n",
    "                f = []\n",
    "                for i in lst:\n",
    "                    objs = []\n",
    "                    for b in i:\n",
    "                        for c in b:\n",
    "                            objs.append(c['label'])\n",
    "                    f.append(objs)\n",
    "            name = path.split('full_')[1]\n",
    "            with open(os.path.join(output_dir, name), 'w') as fw:\n",
    "                json.dump(f, fw)\n",
    "\n",
    "# Загрузка данных и обучение модели\n",
    "def load_data(directory_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category in os.listdir(directory_path):\n",
    "        category_path = os.path.join(directory_path, category)\n",
    "        if os.path.isfile(category_path):\n",
    "            with open(category_path, 'r') as file:\n",
    "                lists_of_words = json.load(file)\n",
    "                for word_list in lists_of_words:\n",
    "                    data.append(' '.join(word_list))\n",
    "                    labels.append(category)\n",
    "    return data, labels\n",
    "\n",
    "# Обучение модели классификации\n",
    "def train_classifier(data, labels):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    random_forest_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_rf = random_forest_model.predict(X_test)\n",
    "    print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "    \n",
    "    return random_forest_model, vectorizer\n",
    "\n",
    "# Предсказание категории для нового списка объектов\n",
    "def predict_category(word_list, model, vectorizer):\n",
    "    word_list_joined = ' '.join(word_list)\n",
    "    vectorized_word_list = vectorizer.transform([word_list_joined])\n",
    "    return model.predict(vectorized_word_list)[0]\n",
    "\n",
    "# Функция для сохранения модели и векторизатора\n",
    "def save_model(model, vectorizer, model_filename, vectorizer_filename):\n",
    "    joblib.dump(model, model_filename)\n",
    "    joblib.dump(vectorizer, vectorizer_filename)\n",
    "    print(f\"Model saved as {model_filename} and vectorizer saved as {vectorizer_filename}\")\n",
    "\n",
    "# Функция для загрузки модели и векторизатора\n",
    "def load_model(model_filename, vectorizer_filename):\n",
    "    model = joblib.load(model_filename)\n",
    "    vectorizer = joblib.load(vectorizer_filename)\n",
    "    print(f\"Model loaded from {model_filename} and vectorizer loaded from {vectorizer_filename}\")\n",
    "    return model, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основная функция пайплайна\n",
    "def main_pipeline():\n",
    "    # Шаг 1: Загрузка моделей\n",
    "    faster_rcnn_model = load_models()\n",
    "\n",
    "    # Шаг 2: Пути к изображениям\n",
    "    paths = [\n",
    "       '/Users/diana/PycharmProjects/OZON/dataset/test'\n",
    "    ]\n",
    "    \n",
    "    output_dir = 'all_data'\n",
    "    output_dir_last = 'clean_data'\n",
    "\n",
    "   #  # Шаг 3: Обработка изображений\n",
    "   #  process_images_in_directories(paths, faster_rcnn_model, output_dir)\n",
    "    \n",
    "    # Шаг 4: Фильтрация данных\n",
    "    filter_data(output_dir, output_dir_last)\n",
    "    \n",
    "    # Шаг 5: Загрузка данных и обучение модели\n",
    "    data, labels = load_data(output_dir_last)\n",
    "    random_forest_model, vectorizer = train_classifier(data, labels)\n",
    "\n",
    "    # Шаг 6: Сохранение модели после обучения\n",
    "    save_model(random_forest_model, vectorizer, 'random_forest_model.pkl', 'vectorizer.pkl')\n",
    "    \n",
    "    # Шаг 7: Загрузка модели\n",
    "    random_forest_model, vectorizer = load_model('random_forest_model.pkl', 'vectorizer.pkl')\n",
    "\n",
    "\n",
    "    # Шаг 8: Предсказание категории для нового списка объектов\n",
    "    new_word_list = [\"vase\", \"dining table\", \"tv\", \"chair\", \"laptop\", \"clock\", \"umbrella\", \"book\", \"cake\", \"potted plant\"]\n",
    "    predicted_category_rf = predict_category(new_word_list, random_forest_model, vectorizer)\n",
    "    print(\"Predicted category (Random Forest):\", predicted_category_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diana/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/diana/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8541353383458646\n",
      "Model saved as random_forest_model.pkl and vectorizer saved as vectorizer.pkl\n",
      "Model loaded from random_forest_model.pkl and vectorizer loaded from vectorizer.pkl\n",
      "Predicted category (Random Forest): стол.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
