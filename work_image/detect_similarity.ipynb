{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение схожести между двумя объектами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/annapetrov/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:03<00:00, 12.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context\n",
    "\n",
    "# Загрузка предобученной модели ResNet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-1])  # Удаление последнего слоя классификации\n",
    "model.eval()\n",
    "\n",
    "# Преобразования для изображений\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path, model):\n",
    "    image = Image.open(image_path)\n",
    "    image = preprocess(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = model(image).squeeze().numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Похожи ли изображения: True, Схожесть: 0.60\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def are_images_similar(image_path1, image_path2, model, threshold=0.5):\n",
    "    features1 = extract_features(image_path1, model)\n",
    "    features2 = extract_features(image_path2, model)\n",
    "    similarity = 1 - cosine(features1, features2)\n",
    "    return similarity > threshold, similarity\n",
    "\n",
    "# Пример использования\n",
    "image_path1 = '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/чехлы/ч4/6810155852.webp'\n",
    "image_path2 = '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/чехлы/ч4/6810156155.webp'\n",
    "image_path3 = '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/Наушники/н8/6836725625.webp'\n",
    "image_path4 = '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/платья/2/7057584592.webp'\n",
    "image_path5 = '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/платья/2/7057584629.webp'\n",
    "image_path6 = '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/платья/9/6795482421.webp'\n",
    "similar, similarity_score = are_images_similar(image_path4, image_path6, model)\n",
    "print(f\"Похожи ли изображения: {similar}, Схожесть: {similarity_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение объектов на изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annapetrov/Desktop/ozon_хакатон/detect_object/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/annapetrov/Desktop/ozon_хакатон/detect_object/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обнаруженные объекты: []\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "# Загрузка модели для детекции объектов\n",
    "object_detection_model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "object_detection_model.eval()\n",
    "\n",
    "# Преобразования для детекции\n",
    "detection_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "def detect_objects(image_path, model, threshold=0.5):\n",
    "    image = Image.open(image_path)\n",
    "    image_tensor = detection_transform(image)\n",
    "    with torch.no_grad():\n",
    "        predictions = model([image_tensor])[0]\n",
    "    \n",
    "    detected_objects = []\n",
    "    for idx, score in enumerate(predictions['scores']):\n",
    "        if score > threshold:\n",
    "            label = predictions['labels'][idx].item()\n",
    "            box = predictions['boxes'][idx].tolist()\n",
    "            detected_objects.append((label, box, score.item()))\n",
    "    \n",
    "    return detected_objects\n",
    "\n",
    "# Пример использования\n",
    "image_path = '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/чехлы/ч4/6810155852.webp'\n",
    "detected_objects = detect_objects(image_path, object_detection_model)\n",
    "print(f\"Обнаруженные объекты: {detected_objects}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение схожести между списком объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = ['/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/Наушники/н9/6971608467.webp',\n",
    "               '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/чехлы/ч2/7021439607.webp',\n",
    "               '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/чехлы/ч4/6810155850.webp',\n",
    "               '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/платья/9/6795482421.webp',\n",
    "               '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/чехлы/ч4/6810156140.webp',\n",
    "               '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/чехлы/ч9/7061090493.webp',\n",
    "               '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/Наушники/н3/6873617147.webp',\n",
    "               '/Users/annapetrov/Desktop/ozon_хакатон/hakaton_ozon_opg/dataset/Наушники/н8/6122417752.webp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластеры изображений: [2 1 1 2 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def cluster_images(image_paths, model, n_clusters=3):\n",
    "    features = np.array([extract_features(image_path, model) for image_path in image_paths])\n",
    "    \n",
    "    # Для снижения размерности (опционально)\n",
    "    min_samples = min(len(image_paths), features.shape[1])\n",
    "    n_components = min(50, min_samples - 1)  # Убедиться, что n_components допустимо\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "    \n",
    "    # Кластеризация\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(reduced_features)\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "clusters = cluster_images(image_paths, model, n_clusters=3)\n",
    "print(f\"Кластеры изображений: {clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластеры изображений: [2 1 1 2 1 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "def cluster_images_without_pca(image_paths, model, n_clusters=3):\n",
    "    features = np.array([extract_features(image_path, model) for image_path in image_paths])\n",
    "    \n",
    "    # Кластеризация\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(features)\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "clusters = cluster_images_without_pca(image_paths, model, n_clusters=3)\n",
    "print(f\"Кластеры изображений: {clusters}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
